{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile as wavf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSplitIndexes(filename):\n",
    "    filename='test/fullSentence/'+filename\n",
    "    \n",
    "    def isNaN(x):\n",
    "        return x != x\n",
    "    signal,sample_rate = librosa.load(filename)\n",
    "    \n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] < 0:\n",
    "            signal[i] = -signal[i]\n",
    "    \n",
    "    index_list = []\n",
    "    j = 0\n",
    "    while j < len(signal):\n",
    "        index_list.append(j)\n",
    "        j = j + 1\n",
    "        \n",
    "    df = pd.DataFrame(list(zip(index_list, signal)),columns =['time', 'signal'])\n",
    "    \n",
    "    df['mov_avg'] = df['signal'].rolling(10000).sum()\n",
    "    \n",
    "    smooth_list = df['mov_avg'].tolist()\n",
    "    #print(len(smooth_list))\n",
    "    \n",
    "    minimas = []\n",
    "    i = 1\n",
    "    while isNaN(smooth_list[i]):\n",
    "        i = i + 1\n",
    "    \n",
    "    #print(i)\n",
    "    window = 15000\n",
    "\n",
    "    while i + window < len(smooth_list):\n",
    "        #print(\"hi\")\n",
    "        m = min(smooth_list[i:i+window])\n",
    "        idx = smooth_list.index(m)\n",
    "        #print(m,idx,smooth_list[i],smooth_list[i+window-1])\n",
    "        \n",
    "        if m != smooth_list[i] and m != smooth_list[i+window-1]:\n",
    "            if len(minimas) != 0  and abs(idx - minimas[-1][0]) > 5000:  \n",
    "                minimas.append([idx,m])\n",
    "            if len(minimas) == 0:\n",
    "                minimas.append([idx,m])\n",
    "    \n",
    "        i = i + window\n",
    "\n",
    "    print(minimas)\n",
    "    return minimas\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitWaveFile(fileName):\n",
    "    splitIndexes = getSplitIndexes(fileName)\n",
    "    signal,sample_rate = librosa.load('test/fullSentence/'+fileName)\n",
    "    splitIndexes.insert(0, [0,0])\n",
    "    for i in range(1,len(splitIndexes)):\n",
    "        subSignal=signal[splitIndexes[i-1][0]:splitIndexes[i][0]]\n",
    "        subSignal = np.array(subSignal* (1<<15), dtype=np.int16)\n",
    "        audio_segment = AudioSegment(\n",
    "            subSignal.tobytes(), \n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=subSignal.dtype.itemsize, \n",
    "            channels=1\n",
    "        )\n",
    "        audio_segment.export(\"test/original/\"+fileName.split(\".\")[0]+\"_\"+str(i)+\".wav\",format=\"wav\")\n",
    "    \n",
    "    subSignal=signal[splitIndexes[-1][0]:]\n",
    "    subSignal = np.array(subSignal* (1<<15), dtype=np.int16)\n",
    "    audio_segment = AudioSegment(\n",
    "            subSignal.tobytes(), \n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=subSignal.dtype.itemsize, \n",
    "            channels=1\n",
    "    )\n",
    "    audio_segment.export(\"test/original/\"+fileName.split(\".\")[0]+\"_\"+str(len(splitIndexes))+\".wav\",format=\"wav\")\n",
    "    return len(splitIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(fileName):\n",
    "    def originalToScaled(fileName):\n",
    "        signal,sample_rate=librosa.load(\"test/original/\"+fileName)\n",
    "        obsMax = max(signal)\n",
    "        obsMin = 0\n",
    "\n",
    "        newMax = 0.1\n",
    "        newMin = 0\n",
    "\n",
    "        new_signal = []\n",
    "\n",
    "        for ele in signal:\n",
    "            ele = abs(ele)\n",
    "            x = (newMax - newMin)/(obsMax - obsMin)*(ele - obsMin) + newMin\n",
    "            new_signal.append(x)\n",
    "\n",
    "        new_signal = np.array(new_signal)\n",
    "\n",
    "        for i in range(len(signal)):\n",
    "            if signal[i] < 0:\n",
    "                new_signal[i] = 0 - new_signal[i]\n",
    "\n",
    "        new_signal = np.array(new_signal* (1<<15), dtype=np.int16)\n",
    "\n",
    "        audio_segment = AudioSegment(\n",
    "        new_signal.tobytes(), \n",
    "        frame_rate=sample_rate,\n",
    "        sample_width=new_signal.dtype.itemsize, \n",
    "        channels=1\n",
    "        )\n",
    "\n",
    "        audio_segment.export(\"test/scaled/\"+fileName,format=\"wav\")\n",
    "        \n",
    "    \n",
    "    def scaledToTrimmed(fileName):\n",
    "        def detect_leading_silence(sound, silence_threshold=-45.0, chunk_size=10):\n",
    "            '''\n",
    "            sound is a pydub.AudioSegment\n",
    "            silence_threshold in dB\n",
    "            chunk_size in ms\n",
    "\n",
    "            iterate over chunks until you find the first one with sound\n",
    "            '''\n",
    "            trim_ms = 0 # ms\n",
    "\n",
    "            assert chunk_size > 0 # to avoid infinite loop\n",
    "            while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold and trim_ms < len(sound):\n",
    "                trim_ms += chunk_size\n",
    "\n",
    "            return trim_ms\n",
    "\n",
    "        sound = AudioSegment.from_file(\"test/scaled/\"+fileName, format=\"wav\")\n",
    "\n",
    "        start_trim = detect_leading_silence(sound)\n",
    "        end_trim = detect_leading_silence(sound.reverse())\n",
    "\n",
    "        duration = len(sound)    \n",
    "        trimmed_sound = sound[start_trim:duration-end_trim]\n",
    "        trimmed_sound.export(\"test/trimmed/\"+fileName, format=\"wav\")\n",
    "\n",
    "    def trimmedToSpeedChange(fileName):\n",
    "        targetLen=20000\n",
    "        sound = AudioSegment.from_file(\"test/trimmed/\"+fileName)\n",
    "        sample = sound.get_array_of_samples()\n",
    "        sample = np.array(sample)\n",
    "        sampleLen=len(sample)\n",
    "\n",
    "        def speed_change(sound, speed):\n",
    "\n",
    "            sound_with_altered_frame_rate = sound._spawn(sound.raw_data, overrides={\n",
    "                \"frame_rate\": int(sound.frame_rate * speed)\n",
    "            })\n",
    "            sound_with_altered_frame_rate.export('test/speedChange/'+fileName, format =\"wav\")\n",
    "\n",
    "        slow_sound = speed_change(sound, sampleLen/targetLen)\n",
    "    \n",
    "    originalToScaled(fileName)\n",
    "    scaledToTrimmed(fileName)\n",
    "    trimmedToSpeedChange(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordPredictor(sentence):\n",
    "    sol = []\n",
    "    if len(sentence.split()) == 1:\n",
    "        encoded_text = tokenizerOne.texts_to_sequences([sentence])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=1, truncating='pre')\n",
    "        print(encoded_text, pad_encoded)\n",
    "        for i in (modelOne.predict(pad_encoded)[0]).argsort()[-5:][::-1]:\n",
    "          pred_word = tokenizerOne.index_word[i]\n",
    "          sol.append(pred_word)\n",
    "            \n",
    "    elif len(sentence.split()) == 2:\n",
    "        encoded_text = tokenizerTwo.texts_to_sequences([sentence])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=2, truncating='pre')\n",
    "        print(encoded_text, pad_encoded)\n",
    "        for i in (modelTwo.predict(pad_encoded)[0]).argsort()[-3:][::-1]:\n",
    "          pred_word = tokenizerTwo.index_word[i]\n",
    "          sol.append(pred_word)\n",
    "            \n",
    "    else:\n",
    "        encoded_text = tokenizerThree.texts_to_sequences([sentence])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=3, truncating='pre')\n",
    "        print(encoded_text, pad_encoded)\n",
    "        for i in (modelThree.predict(pad_encoded)[0]).argsort()[-3:][::-1]:\n",
    "          pred_word = tokenizerThree.index_word[i]\n",
    "          sol.append(pred_word)\n",
    "            \n",
    "    return sol\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(chunk_data,classes):\n",
    "    df = pd.read_csv(r\"references.csv\")\n",
    "    print(\"classes = \", classes)\n",
    "\n",
    "    def features_extractor(file):\n",
    "        audio,sample_rate = librosa.load(file , res_type = 'kaiser_fast')\n",
    "        mfccs_features = librosa.feature.mfcc(y = audio,sr = sample_rate, n_mfcc=40)\n",
    "        mfccs_scaled_features = np.mean(mfccs_features.T,axis = 0)\n",
    "        return mfccs_scaled_features\n",
    "    \n",
    "    extracted_features = []\n",
    "    #classes = [\"plumbing\",\"iro\",\"service\",\"when\"]\n",
    "    #audio_path_dir =str(\"C:Users\\sai\\Desktop\\Capstone project\\DL\\coding\\audio_data\")\n",
    "    cwd = os.getcwd()\n",
    "    for i in df.index:\n",
    "        class_name = df['class_name'][i]\n",
    "\n",
    "        audio_file_name = str(df['file_name'][i])\n",
    "\n",
    "        if class_name in classes:\n",
    "            #audio_path = cwd + \"\\\\audio_data\\\\\" + audio_file_name + \".wav\"\n",
    "            audio_path = \"train/speedChange/\" +   audio_file_name\n",
    "            #print(audio_path)\n",
    "            data = features_extractor(audio_path)\n",
    "            extracted_features.append([class_name,data])\n",
    "            \n",
    "    df_extracted_features = pd.DataFrame(extracted_features,columns = ['class_name' , 'feature_vector'])\n",
    "    \n",
    "    mini_df = df_extracted_features\n",
    "    \n",
    "    X = np.array(mini_df['feature_vector'].tolist())\n",
    "    y = np.array(mini_df['class_name'].tolist())\n",
    "    \n",
    "    #y = np.array(pd.get_dummies(y))\n",
    "    labelencoder=LabelEncoder()\n",
    "#     print('Y before',y)\n",
    "    y=labelencoder.fit_transform(y)\n",
    "#     print('Y integer',y)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    y = y.reshape(len(y), 1)\n",
    "    y = onehot_encoder.fit_transform(y)\n",
    "#     y=to_categorical(labelencoder.fit_transform(y))\n",
    "#     labelencoder.fit(y)\n",
    "#     y=labelencoder.transform(y)\n",
    "#     y=np.array([[i]for i in y])\n",
    "#     print('Y after',y)\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 0)\n",
    "#     print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    num_labels=y.shape[1]\n",
    "    model=Sequential()\n",
    "    ###first layer\n",
    "    model.add(Dense(100,input_shape=(40,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    ###second layer\n",
    "    model.add(Dense(200))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    ###third layer\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    ###final layer\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "    from datetime import datetime \n",
    "    num_epochs = 500\n",
    "    num_batch_size = 4\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=0)\n",
    "    test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "    print(\"Test Accuracy\",test_accuracy[1])\n",
    "    #Preditcting the class\n",
    "    \n",
    "    mfccs_features = librosa.feature.mfcc(y = chunk_data , sr=22050, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "    \n",
    "    predicted_label = model.predict_classes(mfccs_scaled_features)\n",
    "    predict_probability=model.predict(mfccs_scaled_features)\n",
    "    print(\"Predcited Label\",predicted_label)\n",
    "    print(\"Predcited Prob\",predict_probability)\n",
    "\n",
    "    prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "    print(\"Predcited Class\",prediction_class[0])\n",
    "    return prediction_class[0]    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(filename,totalFiles):\n",
    "    cur_sentence = \"s\"\n",
    "    for i in range(1,totalFiles+1):\n",
    "        X,sample_rate=librosa.load('test/speedChange/'+fileName.split(\".\")[0]+\"_\"+str(i)+\".wav\" , res_type = 'kaiser_fast')\n",
    "        classes = wordPredictor(cur_sentence)\n",
    "        cur_sentence = cur_sentence + \" \" + predict(X,classes)\n",
    "    return cur_sentence\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelOne = load_model(\"../wordPredictor/modelOne/modelOne.h5\")\n",
    "modelTwo = load_model(\"../wordPredictor/modelTwo/modelTwo.h5\")\n",
    "modelThree = load_model(\"../wordPredictor/modelThree/modelThree.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../wordPredictor/modelOne/tokenizerOne.tokenizer', 'rb') as config_dictionary_file:\n",
    "    tokenizerOne = pickle.load(config_dictionary_file)\n",
    "\n",
    "with open('../wordPredictor/modelTwo/tokenizerTwo.tokenizer', 'rb') as config_dictionary_file:\n",
    "    tokenizerTwo = pickle.load(config_dictionary_file)\n",
    "\n",
    "with open('../wordPredictor/modelThree/tokenizerThree.tokenizer', 'rb') as config_dictionary_file:\n",
    "    tokenizerThree = pickle.load(config_dictionary_file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37809, 13.05748274519064], [65385, 12.928407609132792], [89288, 14.55607221989402]]\n"
     ]
    }
   ],
   "source": [
    "fileName = 'ad_58_1.wav'   \n",
    "totalFiles=splitWaveFile(fileName)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,totalFiles+1):\n",
    "    preProcess(fileName.split(\".\")[0]+\"_\"+str(i)+\".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [[1]]\n",
      "classes =  ['what', 'hathira', 'hathiradha', 'are', 'nanna']\n",
      "Test Accuracy 0.8666666746139526\n",
      "Predcited Label [3]\n",
      "Predcited Prob [[2.7357256e-16 1.4512064e-10 7.0856374e-13 1.0000000e+00 2.2851456e-18]]\n",
      "Predcited Class nanna\n",
      "[1, 21] [[ 1 21]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes =  ['hathira', 'next', 'traffic']\n",
      "Test Accuracy 0.8888888955116272\n",
      "Predcited Label [2]\n",
      "Predcited Prob [[9.1540682e-07 1.1221816e-09 9.9999905e-01]]\n",
      "Predcited Class traffic\n",
      "[1, 30, 56] [[ 1 30 56]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CF31BED558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "classes =  ['stations', 'plumbing', 'kolaayi']\n",
      "Test Accuracy 0.8888888955116272\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CF31BED1F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Predcited Label [1]\n",
      "Predcited Prob [[4.7260551e-07 9.9999952e-01 5.4003734e-14]]\n",
      "Predcited Class plumbing\n",
      "[1, 30, 56, 35] [[30 56 35]]\n",
      "classes =  ['yavdu', 'service', 'open']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.29629629850387573\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CF32F67558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Predcited Label [2]\n",
      "Predcited Prob [[0.3330005  0.31862897 0.34837055]]\n",
      "Predcited Class yavdu\n",
      "s nanna traffic plumbing yavdu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "final_output = speech_to_text(fileName,totalFiles)\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "signal,sample_rate=librosa.load(\"train/original/dr_nanna_2.wav\")\n",
    "lenSignal=len(signal)\n",
    "librosa.display.waveplot(signal,sr=sample_rate)\n",
    "lenSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "signal,sample_rate=librosa.load(\"train/trimmed/dr_nanna_2.wav\")\n",
    "lenSignal=len(signal)\n",
    "librosa.display.waveplot(signal,sr=sample_rate)\n",
    "lenSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "signal,sample_rate=librosa.load(\"test/speedChange/testaudio1.wav\")\n",
    "lenSignal=len(signal)\n",
    "librosa.display.waveplot(signal,sr=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preProcess(\"dr_nanna_1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
