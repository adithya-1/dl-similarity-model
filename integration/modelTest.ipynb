{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile as wavf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(chunk_data,classes):\n",
    "    \n",
    "    df = pd.read_csv(r\"references.csv\")\n",
    "    print(\"classes = \", classes)\n",
    "\n",
    "    def features_extractor(file):\n",
    "        audio,sample_rate = librosa.load(file , res_type = 'kaiser_fast')\n",
    "        mfccs_features = librosa.feature.mfcc(y = audio,sr = sample_rate, n_mfcc=40)\n",
    "        mfccs_scaled_features = np.mean(mfccs_features.T,axis = 0)\n",
    "        return mfccs_scaled_features\n",
    "    \n",
    "    extracted_features = []\n",
    "    #classes = [\"plumbing\",\"iro\",\"service\",\"when\"]\n",
    "    #audio_path_dir =str(\"C:Users\\sai\\Desktop\\Capstone project\\DL\\coding\\audio_data\")\n",
    "    cwd = os.getcwd()\n",
    "    for i in df.index:\n",
    "        class_name = df['class_name'][i]\n",
    "\n",
    "        audio_file_name = str(df['file_name'][i])\n",
    "\n",
    "        if class_name in classes:\n",
    "            #audio_path = cwd + \"\\\\audio_data\\\\\" + audio_file_name + \".wav\"\n",
    "            audio_path = \"D:\\PES\\Capstone\\phase two\" + \"\\wav\\\\\" +   audio_file_name\n",
    "            #print(audio_path)\n",
    "            data = features_extractor(audio_path)\n",
    "            extracted_features.append([class_name,data])\n",
    "            \n",
    "    df_extracted_features = pd.DataFrame(extracted_features,columns = ['class_name' , 'feature_vector'])\n",
    "    \n",
    "    mini_df = df_extracted_features\n",
    "    \n",
    "    X = np.array(mini_df['feature_vector'].tolist())\n",
    "    y = np.array(mini_df['class_name'].tolist())\n",
    "    \n",
    "    #y = np.array(pd.get_dummies(y))\n",
    "    labelencoder=LabelEncoder()\n",
    "    print('Y before',y)\n",
    "    y=labelencoder.fit_transform(y)\n",
    "    print('Y integer',y)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    y = y.reshape(len(y), 1)\n",
    "    y = onehot_encoder.fit_transform(y)\n",
    "#     y=to_categorical(labelencoder.fit_transform(y))\n",
    "#     labelencoder.fit(y)\n",
    "#     y=labelencoder.transform(y)\n",
    "#     y=np.array([[i]for i in y])\n",
    "    print('Y after',y)\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 0)\n",
    "#     print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    num_labels=y.shape[1]\n",
    "    model=Sequential()\n",
    "    ###first layer\n",
    "    model.add(Dense(100,input_shape=(40,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    ###second layer\n",
    "    model.add(Dense(200))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    ###third layer\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    ###final layer\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "    from datetime import datetime \n",
    "\n",
    "    num_epochs = 500\n",
    "    num_batch_size = 4\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=0)\n",
    "    test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "    print(\"Test Accuracy\",test_accuracy[1])\n",
    "    \n",
    "    \n",
    "    #Preditcting the class\n",
    "    audio,sample_rate = librosa.load('test/nanna_test.wav' , res_type = 'kaiser_fast')\n",
    "    mfccs_features = librosa.feature.mfcc(y = audio , sr=22050, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "    \n",
    "    predicted_label = model.predict_classes(mfccs_scaled_features)\n",
    "    \n",
    "    print(\"Predcited Label\",predicted_label)\n",
    "    prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "    print(\"Predcited Class\",prediction_class[0])\n",
    "    return prediction_class[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes =  ['what', 'hathira', 'hathiradha', 'are', 'nanna']\n",
      "Y before ['are' 'are' 'are' 'are' 'are' 'hathiradha' 'hathiradha' 'hathiradha'\n",
      " 'hathiradha' 'hathiradha' 'hathira' 'hathira' 'hathira' 'hathira'\n",
      " 'hathira' 'nanna' 'nanna' 'nanna' 'nanna' 'nanna' 'what' 'what' 'what'\n",
      " 'what' 'what' 'are' 'are' 'are' 'are' 'are' 'hathiradha' 'hathiradha'\n",
      " 'hathiradha' 'hathiradha' 'hathiradha' 'hathira' 'hathira' 'hathira'\n",
      " 'hathira' 'hathira' 'nanna' 'nanna' 'nanna' 'nanna' 'nanna' 'what' 'what'\n",
      " 'what' 'what' 'what' 'are' 'are' 'are' 'are' 'are' 'hathiradha'\n",
      " 'hathiradha' 'hathiradha' 'hathiradha' 'hathiradha' 'hathira' 'hathira'\n",
      " 'hathira' 'hathira' 'hathira' 'nanna' 'nanna' 'nanna' 'nanna' 'nanna'\n",
      " 'what' 'what' 'what' 'what' 'what']\n",
      "Y integer [0 0 0 0 0 2 2 2 2 2 1 1 1 1 1 3 3 3 3 3 4 4 4 4 4 0 0 0 0 0 2 2 2 2 2 1 1\n",
      " 1 1 1 3 3 3 3 3 4 4 4 4 4 0 0 0 0 0 2 2 2 2 2 1 1 1 1 1 3 3 3 3 3 4 4 4 4\n",
      " 4]\n",
      "Y after [[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "output=predict([],['what', 'hathira', 'hathiradha', 'are', 'nanna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
