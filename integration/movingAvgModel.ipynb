{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile as wavf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import copy\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSplitIndexes(filename):\n",
    "    filename='test/fullSentence/'+filename\n",
    "    \n",
    "    def isNaN(x):\n",
    "        return x != x\n",
    "    signal,sample_rate = librosa.load(filename)\n",
    "    \n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] < 0:\n",
    "            signal[i] = -signal[i]\n",
    "    \n",
    "    index_list = []\n",
    "    j = 0\n",
    "    while j < len(signal):\n",
    "        index_list.append(j)\n",
    "        j = j + 1\n",
    "        \n",
    "    df = pd.DataFrame(list(zip(index_list, signal)),columns =['time', 'signal'])\n",
    "    \n",
    "    df['mov_avg'] = df['signal'].rolling(10000).sum()\n",
    "    \n",
    "    smooth_list = df['mov_avg'].tolist()\n",
    "    #print(len(smooth_list))\n",
    "    \n",
    "    minimas = []\n",
    "    i = 1\n",
    "    while isNaN(smooth_list[i]):\n",
    "        i = i + 1\n",
    "    \n",
    "    #print(i)\n",
    "    window = 15000\n",
    "\n",
    "    while i + window < len(smooth_list):\n",
    "        #print(\"hi\")\n",
    "        m = min(smooth_list[i:i+window])\n",
    "        idx = smooth_list.index(m)\n",
    "        #print(m,idx,smooth_list[i],smooth_list[i+window-1])\n",
    "        \n",
    "        if m != smooth_list[i] and m != smooth_list[i+window-1]:\n",
    "            if len(minimas) != 0  and abs(idx - minimas[-1][0]) > 5000:  \n",
    "                minimas.append([idx,m])\n",
    "            if len(minimas) == 0:\n",
    "                minimas.append([idx,m])\n",
    "    \n",
    "        i = i + window\n",
    "\n",
    "    print(minimas)\n",
    "    return minimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitWaveFile(fileName):\n",
    "    splitIndexes = getSplitIndexes(fileName)\n",
    "    signal,sample_rate = librosa.load('test/fullSentence/'+fileName)\n",
    "    splitIndexes.insert(0, [0,0])\n",
    "    for i in range(1,len(splitIndexes)):\n",
    "        subSignal=signal[splitIndexes[i-1][0]:splitIndexes[i][0]]\n",
    "        subSignal = np.array(subSignal* (1<<15), dtype=np.int16)\n",
    "        audio_segment = AudioSegment(\n",
    "            subSignal.tobytes(), \n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=subSignal.dtype.itemsize, \n",
    "            channels=1\n",
    "        )\n",
    "        audio_segment.export(\"test/original/\"+fileName.split(\".\")[0]+\"_\"+str(i)+\".wav\",format=\"wav\")\n",
    "    \n",
    "    subSignal=signal[splitIndexes[-1][0]:]\n",
    "    subSignal = np.array(subSignal* (1<<15), dtype=np.int16)\n",
    "    audio_segment = AudioSegment(\n",
    "            subSignal.tobytes(), \n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=subSignal.dtype.itemsize, \n",
    "            channels=1\n",
    "    )\n",
    "    audio_segment.export(\"test/original/\"+fileName.split(\".\")[0]+\"_\"+str(len(splitIndexes))+\".wav\",format=\"wav\")\n",
    "    return len(splitIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(fileName):\n",
    "    def originalToScaled(fileName):\n",
    "        signal,sample_rate=librosa.load(\"test/original/\"+fileName)\n",
    "        obsMax = max(signal)\n",
    "        obsMin = 0\n",
    "\n",
    "        newMax = 0.1\n",
    "        newMin = 0\n",
    "\n",
    "        new_signal = []\n",
    "\n",
    "        for ele in signal:\n",
    "            ele = abs(ele)\n",
    "            x = (newMax - newMin)/(obsMax - obsMin)*(ele - obsMin) + newMin\n",
    "            new_signal.append(x)\n",
    "\n",
    "        new_signal = np.array(new_signal)\n",
    "\n",
    "        for i in range(len(signal)):\n",
    "            if signal[i] < 0:\n",
    "                new_signal[i] = 0 - new_signal[i]\n",
    "\n",
    "        new_signal = np.array(new_signal* (1<<15), dtype=np.int16)\n",
    "\n",
    "        audio_segment = AudioSegment(\n",
    "        new_signal.tobytes(), \n",
    "        frame_rate=sample_rate,\n",
    "        sample_width=new_signal.dtype.itemsize, \n",
    "        channels=1\n",
    "        )\n",
    "\n",
    "        audio_segment.export(\"test/scaled/\"+fileName,format=\"wav\")\n",
    "        \n",
    "    \n",
    "    def scaledToTrimmed(fileName):\n",
    "        def detect_leading_silence(sound, silence_threshold=-50.0, chunk_size=10):\n",
    "            '''\n",
    "            sound is a pydub.AudioSegment\n",
    "            silence_threshold in dB\n",
    "            chunk_size in ms\n",
    "\n",
    "            iterate over chunks until you find the first one with sound\n",
    "            '''\n",
    "            trim_ms = 0 # ms\n",
    "\n",
    "            assert chunk_size > 0 # to avoid infinite loop\n",
    "            while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold and trim_ms < len(sound):\n",
    "                trim_ms += chunk_size\n",
    "\n",
    "            return trim_ms\n",
    "\n",
    "        sound = AudioSegment.from_file(\"test/scaled/\"+fileName, format=\"wav\")\n",
    "\n",
    "        start_trim = detect_leading_silence(sound)\n",
    "        end_trim = detect_leading_silence(sound.reverse())\n",
    "\n",
    "        duration = len(sound)    \n",
    "        trimmed_sound = sound[start_trim:duration-end_trim]\n",
    "        trimmed_sound.export(\"test/trimmed/\"+fileName, format=\"wav\")\n",
    "\n",
    "    def trimmedToSpeedChange(fileName):\n",
    "        targetLen=20000\n",
    "        sound = AudioSegment.from_file(\"test/trimmed/\"+fileName)\n",
    "        sample = sound.get_array_of_samples()\n",
    "        sample = np.array(sample)\n",
    "        sampleLen=len(sample)\n",
    "\n",
    "        def speed_change(sound, speed):\n",
    "\n",
    "            sound_with_altered_frame_rate = sound._spawn(sound.raw_data, overrides={\n",
    "                \"frame_rate\": int(sound.frame_rate * speed)\n",
    "            })\n",
    "            sound_with_altered_frame_rate.export('test/speedChange/'+fileName, format =\"wav\")\n",
    "\n",
    "        slow_sound = speed_change(sound, sampleLen/targetLen)\n",
    "    \n",
    "    originalToScaled(fileName)\n",
    "    scaledToTrimmed(fileName)\n",
    "    trimmedToSpeedChange(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordPredictor(sentence):\n",
    "    sol = []\n",
    "    if len(sentence.split()) == 1:\n",
    "        encoded_text = tokenizerOne.texts_to_sequences([sentence])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=1, truncating='pre')\n",
    "        print(encoded_text, pad_encoded)\n",
    "        for i in (modelOne.predict(pad_encoded)[0]).argsort()[-7:][::-1]:\n",
    "          pred_word = tokenizerOne.index_word[i]\n",
    "          sol.append(pred_word)\n",
    "            \n",
    "    elif len(sentence.split()) == 2:\n",
    "        encoded_text = tokenizerTwo.texts_to_sequences([sentence])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=2, truncating='pre')\n",
    "        print(encoded_text, pad_encoded)\n",
    "        for i in (modelTwo.predict(pad_encoded)[0]).argsort()[-3:][::-1]:\n",
    "          pred_word = tokenizerTwo.index_word[i]\n",
    "          sol.append(pred_word)\n",
    "            \n",
    "    else:\n",
    "        encoded_text = tokenizerThree.texts_to_sequences([sentence])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=3, truncating='pre')\n",
    "        print(encoded_text, pad_encoded)\n",
    "        for i in (modelThree.predict(pad_encoded)[0]).argsort()[-3:][::-1]:\n",
    "          pred_word = tokenizerThree.index_word[i]\n",
    "          sol.append(pred_word)\n",
    "            \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(chunk_data,classes,actualWord):\n",
    "    \n",
    "    df = pd.read_csv(r\"references.csv\")\n",
    "    print(\"classes = \", classes)\n",
    "    if(actualWord not in classes):\n",
    "        classes.append(actualWord)\n",
    "    audio1 = getMovingAvg(chunk_data)\n",
    "    similarities = {}\n",
    "    len1 = len(audio1)\n",
    "    sList = []\n",
    "    for key in moving_avg.keys():\n",
    "        if key in classes:\n",
    "            if key not in similarities:\n",
    "                similarities[key] = []\n",
    "\n",
    "            for audio2 in moving_avg[key]:\n",
    "                len2 = len(audio2)\n",
    "                if(len1 >= len2):\n",
    "                    temp1 = copy.deepcopy(audio1)\n",
    "                    temp2 = copy.deepcopy(audio2)\n",
    "                else:\n",
    "                    temp1 = copy.deepcopy(audio2)\n",
    "                    temp2 = copy.deepcopy(audio1)\n",
    "\n",
    "                while len(temp1) > len(temp2):\n",
    "                    temp1.pop()\n",
    "\n",
    "                S = dot(temp1, temp2)/(norm(temp1)*norm(temp2))\n",
    "                similarities[key].append(S)\n",
    "\n",
    "                sList.append([key,S])\n",
    "        \n",
    "        \n",
    "    for k,v in similarities.items():\n",
    "        similarities[k] = sum(v)/len(v)\n",
    "    \n",
    "    similarityOutput=max(similarities.items(), key=operator.itemgetter(1))[0]\n",
    "    similarities={k: v for k, v in sorted(similarities.items(), key=lambda item: item[1],reverse=True)}\n",
    "    print(similarities)\n",
    "\n",
    "    sList = sorted(sList, key = lambda x: x[1], reverse = True)\n",
    "#     for i in sList[:20]:\n",
    "#         print(i)\n",
    "        \n",
    "    sList = sList[:20]\n",
    "    output_dic = {}\n",
    "    for i in sList:\n",
    "        if i[0] not in output_dic.keys():\n",
    "            output_dic[i[0]] = 0\n",
    "        output_dic[i[0]] += 1\n",
    "    output_dic={k: v for k, v in sorted(output_dic.items(), key=lambda item: item[1],reverse=True)}\n",
    "    print(\"Before weights\",output_dic)\n",
    "    \n",
    "    \n",
    "    weights=[1.0]\n",
    "    for i in range(len(classes)-1):\n",
    "        weights.insert(0,weights[0]+0.2)\n",
    "        \n",
    "    for k,v in output_dic.items():\n",
    "        output_dic[k] = output_dic[k]*(weights[classes.index(k)])\n",
    "    output_dic={k: v for k, v in sorted(output_dic.items(), key=lambda item: item[1],reverse=True)}\n",
    "    print(\"After weights,\",output_dic)\n",
    "    output = max(output_dic.items(), key=operator.itemgetter(1))[0]\n",
    "    output_dic=sorted(output_dic.items(), key=lambda item: item[1])\n",
    "    \n",
    "    return [similarityOutput,output]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelOne = load_model(\"../wordPredictor/modelOne/modelOne.h5\")\n",
    "modelTwo = load_model(\"../wordPredictor/modelTwo/modelTwo.h5\")\n",
    "modelThree = load_model(\"../wordPredictor/modelThree/modelThree.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../wordPredictor/modelOne/tokenizerOne.tokenizer', 'rb') as config_dictionary_file:\n",
    "    tokenizerOne = pickle.load(config_dictionary_file)\n",
    "\n",
    "with open('../wordPredictor/modelTwo/tokenizerTwo.tokenizer', 'rb') as config_dictionary_file:\n",
    "    tokenizerTwo = pickle.load(config_dictionary_file)\n",
    "\n",
    "with open('../wordPredictor/modelThree/tokenizerThree.tokenizer', 'rb') as config_dictionary_file:\n",
    "    tokenizerThree = pickle.load(config_dictionary_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moving_avg.dictionary', 'rb') as config_dictionary_file:\n",
    "    moving_avg = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageAccuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovingAvg(signal):\n",
    "    #signal,sample_rate = librosa.load(filename)\n",
    "    #librosa.display.waveplot(signal,sr=sample_rate)\n",
    "    \n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] < 0:\n",
    "            signal[i] = -signal[i]\n",
    "        \n",
    "    index_list = []\n",
    "    j = 0\n",
    "    while j < len(signal):\n",
    "        index_list.append(j)\n",
    "        j = j + 1\n",
    "        \n",
    "    df = pd.DataFrame(list(zip(index_list, signal)),columns =['time', 'signal'])\n",
    "    \n",
    "    '''sns.set(rc={'figure.figsize':(20,8.27)})\n",
    "    sns.lineplot(x='time',y='signal',data= df)\n",
    "    plt.show()'''\n",
    "    \n",
    "    df['mov_avg'] = df['signal'].rolling(1500).sum()\n",
    "    \n",
    "    '''sns.set(rc={'figure.figsize':(20,8.27)})\n",
    "    sns.lineplot(x='time',y='mov_avg',data= df)\n",
    "    plt.show()'''\n",
    "    #print(df['mov_avg'][1499:])\n",
    "    smooth_list = df['mov_avg'][1499:].to_list()\n",
    "    #print(smooth_list)\n",
    "    return smooth_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(filename,totalFiles):\n",
    "    df = pd.read_csv(\"DL_sample_sentences.csv\")\n",
    "    ID = filename[3:]\n",
    "    ID = ID[:-4]\n",
    "    index = df[\"ID\"].to_list().index(ID)\n",
    "    actualSentence = df[\"Mixed\"].to_list()[index].lower()\n",
    "    print(\"actual_sentence = \",actualSentence)\n",
    "    cur_sentence = \"s\"\n",
    "    actualSentence = actualSentence.split()\n",
    "    simPS = \"\"\n",
    "    weightPS=\" \"\n",
    "    print(totalFiles)\n",
    "    for i in range(1,totalFiles+1):\n",
    "        X,sample_rate=librosa.load('test/speedChange/'+fileName.split(\".\")[0]+\"_\"+str(i)+\".wav\" , res_type = 'kaiser_fast')\n",
    "        classes = wordPredictor(cur_sentence)\n",
    "        funcOutput=predict(X,classes,actualSentence[i-1])\n",
    "        simNextWord=funcOutput[0].lower()\n",
    "        weightNextWord=funcOutput[1].lower()\n",
    "        print(\"Highest Average Similarity Predicted Word \",simNextWord)\n",
    "        print(\"Highest Frequency Predicted Word \",weightNextWord)\n",
    "        simPS +=  \" \" + simNextWord\n",
    "        weightPS +=  \" \" + weightNextWord\n",
    "        cur_sentence = cur_sentence + \" \" + actualSentence[i-1]\n",
    "        \n",
    "    print(\"Highest Average Similarity Predicted Sentence \",simPS)\n",
    "    print(\"Highest Frequency Sentence \",weightPS)\n",
    "\n",
    "    return cur_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37809, 13.05748274519064], [65385, 12.928407609132792], [89288, 14.55607221989402]]\n"
     ]
    }
   ],
   "source": [
    "fileName = 'ad_58_1.wav'   \n",
    "totalFiles=splitWaveFile(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,totalFiles+1):\n",
    "    preProcess(fileName.split(\".\")[0]+\"_\"+str(i)+\".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_sentence =  nanna next turn yenu\n",
      "4\n",
      "[1] [[1]]\n",
      "classes =  ['what', 'hathira', 'hathiradha', 'are', 'nanna', 'how', 'bheti']\n",
      "{'nanna': 0.909999698361957, 'are': 0.8684239185365122, 'hathira': 0.8429909782236167, 'how': 0.8398534559567687, 'hathiradha': 0.8204536981585854, 'bheti': 0.772599791514836, 'what': 0.7635959130542181}\n",
      "Before weights {'nanna': 18, 'are': 2}\n",
      "After weights, {'nanna': 25.2, 'are': 3.1999999999999997}\n",
      "Highest Average Similarity Predicted Word  nanna\n",
      "Highest Frequency Predicted Word  nanna\n",
      "[1, 21] [[ 1 21]]\n",
      "classes =  ['hathira', 'next', 'traffic']\n",
      "{'next': 0.8885499415416608, 'traffic': 0.8581023125049895, 'hathira': 0.5544009349055259}\n",
      "Before weights {'next': 15, 'traffic': 5}\n",
      "After weights, {'next': 18.0, 'traffic': 5.0}\n",
      "Highest Average Similarity Predicted Word  next\n",
      "Highest Frequency Predicted Word  next\n",
      "[1, 30, 31] [[ 1 30 31]]\n",
      "classes =  ['turn', 'places', 'plumbing']\n",
      "{'turn': 0.9567368809176188, 'plumbing': 0.942401906497795, 'places': 0.8536701122846241}\n",
      "Before weights {'turn': 13, 'plumbing': 7}\n",
      "After weights, {'turn': 18.2, 'plumbing': 7.0}\n",
      "Highest Average Similarity Predicted Word  turn\n",
      "Highest Frequency Predicted Word  turn\n",
      "[1, 30, 31, 45] [[30 31 45]]\n",
      "classes =  ['yenu', 'saradi', 'open']\n",
      "{'yenu': 0.9489688363667014, 'saradi': 0.8907351431505826, 'open': 0.8277233043671754}\n",
      "Before weights {'yenu': 20}\n",
      "After weights, {'yenu': 28.0}\n",
      "Highest Average Similarity Predicted Word  yenu\n",
      "Highest Frequency Predicted Word  yenu\n",
      "Highest Average Similarity Predicted Sentence   nanna next turn yenu\n",
      "Highest Frequency Sentence    nanna next turn yenu\n",
      "s nanna next turn yenu\n"
     ]
    }
   ],
   "source": [
    "final_output = speech_to_text(fileName,totalFiles)\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
