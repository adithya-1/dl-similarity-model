{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile as wavf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import copy\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSplitIndexes(filename):\n",
    "    filename='test/fullSentence/'+filename\n",
    "    \n",
    "    def isNaN(x):\n",
    "        return x != x\n",
    "    signal,sample_rate = librosa.load(filename)\n",
    "    \n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] < 0:\n",
    "            signal[i] = -signal[i]\n",
    "    \n",
    "    index_list = []\n",
    "    j = 0\n",
    "    while j < len(signal):\n",
    "        index_list.append(j)\n",
    "        j = j + 1\n",
    "        \n",
    "    df = pd.DataFrame(list(zip(index_list, signal)),columns =['time', 'signal'])\n",
    "    \n",
    "    df['mov_avg'] = df['signal'].rolling(10000).sum()\n",
    "    \n",
    "    smooth_list = df['mov_avg'].tolist()\n",
    "    #print(len(smooth_list))\n",
    "    \n",
    "    minimas = []\n",
    "    i = 1\n",
    "    while isNaN(smooth_list[i]):\n",
    "        i = i + 1\n",
    "    \n",
    "    #print(i)\n",
    "    window = 10000\n",
    "\n",
    "    while i + window < len(smooth_list):\n",
    "        #print(\"hi\")\n",
    "        m = min(smooth_list[i:i+window])\n",
    "        idx = smooth_list.index(m)\n",
    "        #print(m,idx,smooth_list[i],smooth_list[i+window-1])\n",
    "        \n",
    "        if m != smooth_list[i] and m != smooth_list[i+window-1]:\n",
    "            if len(minimas) != 0  and abs(idx - minimas[-1][0]) > 5000:  \n",
    "                minimas.append([idx,m])\n",
    "            if len(minimas) == 0:\n",
    "                minimas.append([idx,m])\n",
    "    \n",
    "        i = i + window\n",
    "\n",
    "    print(minimas)\n",
    "    return minimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitWaveFile(fileName):\n",
    "    splitIndexes = getSplitIndexes(fileName)\n",
    "    signal,sample_rate = librosa.load('test/fullSentence/'+fileName)\n",
    "    splitIndexes.insert(0, [0,0])\n",
    "    for i in range(1,len(splitIndexes)):\n",
    "        subSignal=signal[splitIndexes[i-1][0]:splitIndexes[i][0]]\n",
    "        subSignal = np.array(subSignal* (1<<15), dtype=np.int16)\n",
    "        audio_segment = AudioSegment(\n",
    "            subSignal.tobytes(), \n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=subSignal.dtype.itemsize, \n",
    "            channels=1\n",
    "        )\n",
    "        audio_segment.export(\"test/original/\"+fileName.split(\".\")[0]+\"_\"+str(i)+\".wav\",format=\"wav\")\n",
    "    \n",
    "    subSignal=signal[splitIndexes[-1][0]:]\n",
    "    subSignal = np.array(subSignal* (1<<15), dtype=np.int16)\n",
    "    audio_segment = AudioSegment(\n",
    "            subSignal.tobytes(), \n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=subSignal.dtype.itemsize, \n",
    "            channels=1\n",
    "    )\n",
    "    audio_segment.export(\"test/original/\"+fileName.split(\".\")[0]+\"_\"+str(len(splitIndexes))+\".wav\",format=\"wav\")\n",
    "    return len(splitIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(fileName):\n",
    "    def originalToScaled(fileName):\n",
    "        signal,sample_rate=librosa.load(\"test/original/\"+fileName)\n",
    "        obsMax = max(signal)\n",
    "        obsMin = 0\n",
    "\n",
    "        newMax = 0.1\n",
    "        newMin = 0\n",
    "\n",
    "        new_signal = []\n",
    "\n",
    "        for ele in signal:\n",
    "            ele = abs(ele)\n",
    "            x = (newMax - newMin)/(obsMax - obsMin)*(ele - obsMin) + newMin\n",
    "            new_signal.append(x)\n",
    "\n",
    "        new_signal = np.array(new_signal)\n",
    "\n",
    "        for i in range(len(signal)):\n",
    "            if signal[i] < 0:\n",
    "                new_signal[i] = 0 - new_signal[i]\n",
    "\n",
    "        new_signal = np.array(new_signal* (1<<15), dtype=np.int16)\n",
    "\n",
    "        audio_segment = AudioSegment(\n",
    "        new_signal.tobytes(), \n",
    "        frame_rate=sample_rate,\n",
    "        sample_width=new_signal.dtype.itemsize, \n",
    "        channels=1\n",
    "        )\n",
    "\n",
    "        audio_segment.export(\"test/scaled/\"+fileName,format=\"wav\")\n",
    "        \n",
    "    \n",
    "    def scaledToTrimmed(fileName):\n",
    "        def detect_leading_silence(sound, silence_threshold=-50.0, chunk_size=10):\n",
    "            '''\n",
    "            sound is a pydub.AudioSegment\n",
    "            silence_threshold in dB\n",
    "            chunk_size in ms\n",
    "\n",
    "            iterate over chunks until you find the first one with sound\n",
    "            '''\n",
    "            trim_ms = 0 # ms\n",
    "\n",
    "            assert chunk_size > 0 # to avoid infinite loop\n",
    "            while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold and trim_ms < len(sound):\n",
    "                trim_ms += chunk_size\n",
    "\n",
    "            return trim_ms\n",
    "\n",
    "        sound = AudioSegment.from_file(\"test/scaled/\"+fileName, format=\"wav\")\n",
    "\n",
    "        start_trim = detect_leading_silence(sound)\n",
    "        end_trim = detect_leading_silence(sound.reverse())\n",
    "\n",
    "        duration = len(sound)    \n",
    "        trimmed_sound = sound[start_trim:duration-end_trim]\n",
    "        trimmed_sound.export(\"test/trimmed/\"+fileName, format=\"wav\")\n",
    "\n",
    "    def trimmedToSpeedChange(fileName):\n",
    "        targetLen=20000\n",
    "        sound = AudioSegment.from_file(\"test/trimmed/\"+fileName)\n",
    "        sample = sound.get_array_of_samples()\n",
    "        sample = np.array(sample)\n",
    "        sampleLen=len(sample)\n",
    "\n",
    "        def speed_change(sound, speed):\n",
    "\n",
    "            sound_with_altered_frame_rate = sound._spawn(sound.raw_data, overrides={\n",
    "                \"frame_rate\": int(sound.frame_rate * speed)\n",
    "            })\n",
    "            sound_with_altered_frame_rate.export('test/speedChange/'+fileName, format =\"wav\")\n",
    "\n",
    "        slow_sound = speed_change(sound, sampleLen/targetLen)\n",
    "    \n",
    "    originalToScaled(fileName)\n",
    "    scaledToTrimmed(fileName)\n",
    "    trimmedToSpeedChange(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordPredictor(sentence):\n",
    "    sol = []\n",
    "    if len(sentence.split()) == 1:\n",
    "        encoded_text = tokenizerOne.texts_to_sequences([sentence])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=1, truncating='pre')\n",
    "        print(encoded_text, pad_encoded)\n",
    "        for i in (modelOne.predict(pad_encoded)[0]).argsort()[-5:][::-1]:\n",
    "          pred_word = tokenizerOne.index_word[i]\n",
    "          sol.append(pred_word)\n",
    "            \n",
    "    elif len(sentence.split()) == 2:\n",
    "        encoded_text = tokenizerTwo.texts_to_sequences([sentence])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=2, truncating='pre')\n",
    "        print(encoded_text, pad_encoded)\n",
    "        for i in (modelTwo.predict(pad_encoded)[0]).argsort()[-5:][::-1]:\n",
    "          pred_word = tokenizerTwo.index_word[i]\n",
    "          sol.append(pred_word)\n",
    "            \n",
    "    else:\n",
    "        encoded_text = tokenizerThree.texts_to_sequences([sentence])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=3, truncating='pre')\n",
    "        print(encoded_text, pad_encoded)\n",
    "        for i in (modelThree.predict(pad_encoded)[0]).argsort()[-5:][::-1]:\n",
    "          pred_word = tokenizerThree.index_word[i]\n",
    "          sol.append(pred_word)\n",
    "            \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(chunk_data,classes):\n",
    "    \n",
    "    df = pd.read_csv(r\"references.csv\")\n",
    "    print(\"classes = \", classes)\n",
    "    audio1 = getMovingAvg(chunk_data)\n",
    "    similarities = {}\n",
    "    len1 = len(audio1)\n",
    "    sList = []\n",
    "    for key in moving_avg.keys():\n",
    "        if key in classes:\n",
    "            print(key)\n",
    "            if key not in similarities:\n",
    "                similarities[key] = []\n",
    "\n",
    "            for audio2 in moving_avg[key]:\n",
    "                len2 = len(audio2)\n",
    "                if(len1 >= len2):\n",
    "                    temp1 = copy.deepcopy(audio1)\n",
    "                    temp2 = copy.deepcopy(audio2)\n",
    "                else:\n",
    "                    temp1 = copy.deepcopy(audio2)\n",
    "                    temp2 = copy.deepcopy(audio1)\n",
    "\n",
    "                while len(temp1) > len(temp2):\n",
    "                    temp1.pop()\n",
    "\n",
    "                S = dot(temp1, temp2)/(norm(temp1)*norm(temp2))\n",
    "                #similarities[key].append(S)\n",
    "\n",
    "                sList.append([key,S])\n",
    "        \n",
    "        \n",
    "    '''for k,v in similarities.items():\n",
    "        similarities[k] = sum(v)/len(v)'''\n",
    "    \n",
    "    #print(similarities)\n",
    "    sList = sorted(sList, key = lambda x: x[1], reverse = True)\n",
    "    for i in sList[:20]:\n",
    "        print(i)\n",
    "        \n",
    "    sList = sList[:20]\n",
    "    output_dic = {}\n",
    "    for i in sList:\n",
    "        if i[0] not in output_dic.keys():\n",
    "            output_dic[i[0]] = 0\n",
    "        output_dic[i[0]] += 1\n",
    "    print(output_dic)\n",
    "    \n",
    "    for k,v in output_dic.items():\n",
    "        output_dic[k] = output_dic[k]*(len(classes)-classes.index(k))\n",
    "    output = max(output_dic.items(), key=operator.itemgetter(1))[0]\n",
    "    print(output)\n",
    "    return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelOne = load_model(\"../wordPredictor/modelOne/modelOne.h5\")\n",
    "modelTwo = load_model(\"../wordPredictor/modelTwo/modelTwo.h5\")\n",
    "modelThree = load_model(\"../wordPredictor/modelThree/modelThree.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../wordPredictor/modelOne/tokenizerOne.tokenizer', 'rb') as config_dictionary_file:\n",
    "    tokenizerOne = pickle.load(config_dictionary_file)\n",
    "\n",
    "with open('../wordPredictor/modelTwo/tokenizerTwo.tokenizer', 'rb') as config_dictionary_file:\n",
    "    tokenizerTwo = pickle.load(config_dictionary_file)\n",
    "\n",
    "with open('../wordPredictor/modelThree/tokenizerThree.tokenizer', 'rb') as config_dictionary_file:\n",
    "    tokenizerThree = pickle.load(config_dictionary_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moving_avg.dictionary', 'rb') as config_dictionary_file:\n",
    "    moving_avg = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovingAvg(signal):\n",
    "    #signal,sample_rate = librosa.load(filename)\n",
    "    #librosa.display.waveplot(signal,sr=sample_rate)\n",
    "    \n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] < 0:\n",
    "            signal[i] = -signal[i]\n",
    "        \n",
    "    index_list = []\n",
    "    j = 0\n",
    "    while j < len(signal):\n",
    "        index_list.append(j)\n",
    "        j = j + 1\n",
    "        \n",
    "    df = pd.DataFrame(list(zip(index_list, signal)),columns =['time', 'signal'])\n",
    "    \n",
    "    '''sns.set(rc={'figure.figsize':(20,8.27)})\n",
    "    sns.lineplot(x='time',y='signal',data= df)\n",
    "    plt.show()'''\n",
    "    \n",
    "    df['mov_avg'] = df['signal'].rolling(1500).sum()\n",
    "    \n",
    "    '''sns.set(rc={'figure.figsize':(20,8.27)})\n",
    "    sns.lineplot(x='time',y='mov_avg',data= df)\n",
    "    plt.show()'''\n",
    "    #print(df['mov_avg'][1499:])\n",
    "    smooth_list = df['mov_avg'][1499:].to_list()\n",
    "    #print(smooth_list)\n",
    "    return smooth_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(filename,totalFiles):\n",
    "    cur_sentence = \"s\"\n",
    "    for i in range(1,totalFiles+1):\n",
    "        X,sample_rate=librosa.load('test/speedChange/'+fileName.split(\".\")[0]+\"_\"+str(i)+\".wav\" , res_type = 'kaiser_fast')\n",
    "        classes = wordPredictor(cur_sentence)\n",
    "        cur_sentence = cur_sentence + \" \" + predict(X,classes)\n",
    "    return cur_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32549, 374.84933699758176], [49871, 51.35531058681471], [78211, 256.38533413472464]]\n"
     ]
    }
   ],
   "source": [
    "fileName = '63_5.wav'   \n",
    "totalFiles=splitWaveFile(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test/original/63_51.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[1;32m-> 1184\u001b[1;33m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[0;32m   1185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[1;34m(err, prefix)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error opening 'test/original/63_51.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-80fac33b369f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotalFiles\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpreProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-cb7d1c280bbf>\u001b[0m in \u001b[0;36mpreProcess\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mslow_sound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeed_change\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampleLen\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtargetLen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0moriginalToScaled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mscaledToTrimmed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mtrimmedToSpeedChange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-cb7d1c280bbf>\u001b[0m in \u001b[0;36moriginalToScaled\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moriginalToScaled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0msignal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test/original/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mobsMax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mobsMin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\audioread\\rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test/original/63_51.wav'"
     ]
    }
   ],
   "source": [
    "for i in range(1,totalFiles+1):\n",
    "    preProcess(fileName.split(\".\")[0]+str(i)+\".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [[1]]\n",
      "classes =  ['what', 'hathira', 'hathiradha', 'are', 'nanna']\n",
      "are\n",
      "hathiradha\n",
      "hathira\n",
      "nanna\n",
      "what\n",
      "['nanna', 0.9834670218054491]\n",
      "['nanna', 0.9829499082868363]\n",
      "['nanna', 0.982752354005489]\n",
      "['nanna', 0.9819257443413849]\n",
      "['nanna', 0.9801770253576653]\n",
      "['nanna', 0.9782364985989283]\n",
      "['nanna', 0.971478190069367]\n",
      "['nanna', 0.9713339047362822]\n",
      "['nanna', 0.9705585277894805]\n",
      "['nanna', 0.9682829812879572]\n",
      "['nanna', 0.9670824371587969]\n",
      "['nanna', 0.9642955264865968]\n",
      "['are', 0.963964258510438]\n",
      "['nanna', 0.9605712778951733]\n",
      "['are', 0.9601922813073972]\n",
      "['nanna', 0.9554646116569142]\n",
      "['nanna', 0.9536273890976981]\n",
      "['nanna', 0.9533234853983653]\n",
      "['nanna', 0.9523982232464864]\n",
      "['nanna', 0.9477318659582269]\n",
      "{'nanna': 18, 'are': 2}\n",
      "nanna\n",
      "[1, 21] [[ 1 21]]\n",
      "classes =  ['hathira', 'next', 'traffic', 'udhyaanavu', 'park']\n",
      "hathira\n",
      "next\n",
      "park\n",
      "traffic\n",
      "udhyaanavu\n",
      "['park', 0.9925708726296217]\n",
      "['park', 0.9894513033829664]\n",
      "['park', 0.9892559950839309]\n",
      "['next', 0.9845736517767497]\n",
      "['park', 0.9844333433583193]\n",
      "['next', 0.9842210661822529]\n",
      "['next', 0.9835430998962633]\n",
      "['park', 0.9794512467603647]\n",
      "['park', 0.9763115117089323]\n",
      "['next', 0.9755257698871123]\n",
      "['next', 0.9745828506302178]\n",
      "['park', 0.9734494696318368]\n",
      "['park', 0.9713796992273599]\n",
      "['next', 0.9701954837109353]\n",
      "['park', 0.9693442708654846]\n",
      "['park', 0.9681610305695003]\n",
      "['next', 0.9669250176572768]\n",
      "['park', 0.9656962494614529]\n",
      "['next', 0.9645873549145796]\n",
      "['park', 0.9598068344912056]\n",
      "{'park': 12, 'next': 8}\n",
      "next\n",
      "[1, 30, 31] [[ 1 30 31]]\n",
      "classes =  ['turn', 'places', 'plumbing', 'stalagalu', 'nearby']\n",
      "nearby\n",
      "places\n",
      "plumbing\n",
      "turn\n",
      "stalagalu\n",
      "['turn', 0.989213794857487]\n",
      "['turn', 0.9836163856717254]\n",
      "['turn', 0.9799516196032256]\n",
      "['turn', 0.9757094217012813]\n",
      "['turn', 0.9745730471631937]\n",
      "['turn', 0.9739807325647968]\n",
      "['plumbing', 0.9720002175777618]\n",
      "['turn', 0.9715166379325512]\n",
      "['plumbing', 0.9688712284570962]\n",
      "['turn', 0.9682449114718362]\n",
      "['plumbing', 0.9673277838583616]\n",
      "['plumbing', 0.9672136441089981]\n",
      "['nearby', 0.9654994139635146]\n",
      "['turn', 0.9645942927431181]\n",
      "['nearby', 0.9644207805303551]\n",
      "['plumbing', 0.9635300899344267]\n",
      "['turn', 0.9627475938404612]\n",
      "['plumbing', 0.9623982078221549]\n",
      "['nearby', 0.9613488676899569]\n",
      "['nearby', 0.9598061867832023]\n",
      "{'turn': 10, 'plumbing': 6, 'nearby': 4}\n",
      "turn\n",
      "[1, 30, 31, 45] [[30 31 45]]\n",
      "classes =  ['yenu', 'saradi', 'open', 'aagothe', 'service']\n",
      "aagothe\n",
      "open\n",
      "saradi\n",
      "service\n",
      "yenu\n",
      "['yenu', 0.9858851178927761]\n",
      "['yenu', 0.9803388805024188]\n",
      "['yenu', 0.9803012613813843]\n",
      "['yenu', 0.9797697891626673]\n",
      "['yenu', 0.9793460997897115]\n",
      "['yenu', 0.9792325653611086]\n",
      "['yenu', 0.9730908871175145]\n",
      "['yenu', 0.9711999062750561]\n",
      "['yenu', 0.9710498156209504]\n",
      "['yenu', 0.9707287472917987]\n",
      "['yenu', 0.9690125901319092]\n",
      "['service', 0.9663708463924621]\n",
      "['service', 0.9637623889335607]\n",
      "['yenu', 0.9628689675219032]\n",
      "['yenu', 0.9619103420215215]\n",
      "['yenu', 0.959585485726217]\n",
      "['yenu', 0.9595259809223233]\n",
      "['yenu', 0.9572086129211158]\n",
      "['yenu', 0.9562788047418204]\n",
      "['service', 0.9560137065214585]\n",
      "{'yenu': 17, 'service': 3}\n",
      "yenu\n",
      "s nanna next turn yenu\n"
     ]
    }
   ],
   "source": [
    "final_output = speech_to_text(fileName,totalFiles)\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
